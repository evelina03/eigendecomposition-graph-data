{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d17316d-49c0-4132-a162-5357128fe418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import CitationFull\n",
    "import torch\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from scipy import linalg\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f159125-4fd8-40c0-a58d-7eaf6bd46fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/data/dataset.py:238: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/data/dataset.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/io/fs.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'Cora'\n",
    "path = osp.join('.', 'data', dataset)\n",
    "dataset = CitationFull(path, dataset)  # dowload or load the Cora dataset\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959e936-de0b-445a-9626-704f77c78ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to a .pth file \n",
    "torch.save(dataset, 'd3_cora.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553e3392-4af4-4f83-ac8f-4eb27a0c38ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseData.node_attrs of Data(x=[19793, 8710], edge_index=[2, 126842], y=[19793])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.node_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ec7440-e2bb-48cf-8424-b70d94a43836",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f41149e-7694-4f71-a4c0-7cde121ff96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19185a94-bf40-45d9-9dcf-9fc90648b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering_on_graph(torch_data, labels, laplacian, number_of_clusters):\n",
    "\n",
    "    adjacency_matrix = to_dense_adj(torch_data.edge_index).squeeze()\n",
    "    # Convert the PyTorch tensor to a NumPy array\n",
    "    adjacency_matrix = adjacency_matrix.numpy()\n",
    "\n",
    "    dimension = len(adjacency_matrix)\n",
    "\n",
    "    # Calculate degree matrix\n",
    "    degree_matrix = np.sum(adjacency_matrix, axis=0) * np.eye(dimension)\n",
    "    \n",
    "\n",
    "    if laplacian == \"sym\":\n",
    "\n",
    "        # Normalized Symmetric laplacian matrix\n",
    "        d_half = linalg.fractional_matrix_power(degree_matrix, -0.5)\n",
    "        laplacian_matrix_normalized = np.matmul(np.matmul(d_half, adjacency_matrix), d_half)\n",
    "\n",
    "    if laplacian == \"rw\":\n",
    "\n",
    "        # Normalized Random Walk laplacian matrix\n",
    "        d_inverse = linalg.fractional_matrix_power(degree_matrix, -1)\n",
    "        laplacian_matrix_normalized = np.matmul(d_inverse, adjacency_matrix)\n",
    "\n",
    "\n",
    "    # Calculating eigenvalues and eigenvectors\n",
    "    e, v = np.linalg.eigh(laplacian_matrix_normalized)\n",
    "\n",
    "    index_largest_gap = np.argmax(np.diff(e))\n",
    "    nb_clusters = index_largest_gap + 1\n",
    "    \n",
    "    # Eigen features for k\n",
    "    k = nb_clusters\n",
    "    X = v[:, -1*k:]\n",
    "\n",
    "    # Kmeans\n",
    "    clustering = KMeans(n_clusters = nb_clusters)\n",
    "    clustering.fit(X)\n",
    "    c_labels = clustering.fit_predict(X)\n",
    "\n",
    "    # Create a copy of the data object by initializing a new Data instance\n",
    "    # final_data = Data(\n",
    "    #     edge_index=torch_data.edge_index,  # edge indices\n",
    "    # )\n",
    "\n",
    "    # final_df = torch_data.copy()\n",
    "    # final_df['c_labels'] = c_labels\n",
    "    # final_df['labels'] = labels\n",
    "    \n",
    "    cluster_labels = clustering.labels_\n",
    "    \n",
    "    return silhouette_score(X, cluster_labels), adjusted_rand_score(labels, cluster_labels), nb_clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d11009-efb9-4e25-ac0c-f03d31855d9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m laplace \u001b[38;5;129;01min\u001b[39;00m laplacian_methods:\n\u001b[1;32m     11\u001b[0m     laplacian\u001b[38;5;241m.\u001b[39mappend(laplace)\n\u001b[0;32m---> 13\u001b[0m     si, ar,cl \u001b[38;5;241m=\u001b[39m \u001b[43mspectral_clustering_on_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlaplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m70\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     silhouette_scores\u001b[38;5;241m.\u001b[39mappend(si)\n\u001b[1;32m     16\u001b[0m     adjusted_rand_scores\u001b[38;5;241m.\u001b[39mappend(ar)\n",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m, in \u001b[0;36mspectral_clustering_on_graph\u001b[0;34m(torch_data, labels, laplacian, number_of_clusters)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Create a copy of the data object by initializing a new Data instance\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# final_data = Data(\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#     edge_index=torch_data.edge_index,  # edge indices\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# final_df['c_labels'] = c_labels\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# final_df['labels'] = labels\u001b[39;00m\n\u001b[1;32m     50\u001b[0m cluster_labels \u001b[38;5;241m=\u001b[39m clustering\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msilhouette_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_labels\u001b[49m\u001b[43m)\u001b[49m, adjusted_rand_score(labels, cluster_labels), nb_clusters\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:141\u001b[0m, in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msilhouette_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:299\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    297\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[1;32m    298\u001b[0m label_freqs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(labels)\n\u001b[0;32m--> 299\u001b[0m \u001b[43mcheck_number_of_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    302\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    303\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[1;32m    304\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/cluster/_unsupervised.py:38\u001b[0m, in \u001b[0;36mcheck_number_of_labels\u001b[0;34m(n_labels, n_samples)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Number of samples.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m n_labels \u001b[38;5;241m<\u001b[39m n_samples:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. Valid values are 2 to n_samples - 1 (inclusive)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;241m%\u001b[39m n_labels\n\u001b[1;32m     41\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)"
     ]
    }
   ],
   "source": [
    "laplacian_methods = [\"sym\", \"rw\"]\n",
    "\n",
    "silhouette_scores = []\n",
    "adjusted_rand_scores = []\n",
    "clusters = []\n",
    "laplacian = []\n",
    "\n",
    "\n",
    "for laplace in laplacian_methods:\n",
    "\n",
    "    laplacian.append(laplace)\n",
    "\n",
    "    si, ar,cl = spectral_clustering_on_graph(data, labels, laplace, 70)\n",
    "\n",
    "    silhouette_scores.append(si)\n",
    "    adjusted_rand_scores.append(ar)\n",
    "    clusters.append(cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966cb12-d207-420c-bce2-c48afd2c6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_cora = pd.DataFrame(list(zip(laplacian,silhouette_scores,adjusted_rand_scores,clusters)), \n",
    "             columns= [\"laplacian\", \"silhouette\", \"adjusted_rand\",\"#_cluster\"])\n",
    "\n",
    "experiment_cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75716c8f-0c9c-4d8c-8d6d-0d02b186fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plot time on the first y-axis\n",
    "ax.plot(experiment_cora['laplacian'], experiment_cora['silhouette'], marker='o', color='b', label='Time (seconds)')\n",
    "\n",
    "# Create a second y-axis\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plot memory on the second y-axis\n",
    "ax2.plot(experiment_cora['laplacian'], experiment_cora['adjusted_rand'], marker='x', color='r', label='Memory (KB)')\n",
    "\n",
    "# Set labels and legends\n",
    "ax.set_xlabel('laplacian')\n",
    "ax.set_ylabel('silhouette', color='b')\n",
    "ax2.set_ylabel('adjusted_rand', color='r')\n",
    "\n",
    "ax.set_ylim(-1.1, 1)\n",
    "ax2.set_ylim(-1.1, 1)  # Adjust the multiplier as needed\n",
    "\n",
    "\n",
    "# Add legends\n",
    "# ax.legend(loc='upper left')\n",
    "# ax2.legend(loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.title('experiment_cora')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cf9f7-cd6f-4577-af2b-f251e7921e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
