{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8dca38c-219d-473e-960e-367dcfea040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.datasets import Cora, CiteSeer, PubMedDiabetes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy.sparse as sp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3087aa44-7aff-4db0-b916-b8bc6d4ca211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitationNetworkVisualizer:\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.graph = None\n",
    "        self.node_subjects = None\n",
    "        self.node_features = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load the specified citation dataset and prepare data for spectral clustering.\"\"\"\n",
    "        if self.dataset_name == 'cora':\n",
    "            dataset = Cora()\n",
    "        elif self.dataset_name == 'citeseer':\n",
    "            dataset = CiteSeer()\n",
    "        elif self.dataset_name == 'pubmed':\n",
    "            dataset = PubMedDiabetes()\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported dataset name. Choose 'cora', 'citeseer', or 'pubmed'.\")\n",
    "        \n",
    "        display(HTML(dataset.description))\n",
    "        self.graph, self.node_subjects = dataset.load()\n",
    "\n",
    "        # Convert the graph to a dense PyTorch tensor\n",
    "        adjacency_matrix = self.graph.to_adjacency_matrix(weighted=False)\n",
    "        # Prepare labels\n",
    "        labels = self.node_subjects.values\n",
    "\n",
    "        feature_matrix = self.graph.node_features()\n",
    "\n",
    "        return feature_matrix, adjacency_matrix, labels\n",
    "\n",
    "    def visualize(self):\n",
    "        \"\"\"Visualize the citation dataset network.\"\"\"\n",
    "        # Convert to NetworkX graph for visualization\n",
    "        G_nx = self.graph.to_networkx()\n",
    "\n",
    "        # Create a network layout\n",
    "        pos = nx.spring_layout(G_nx)\n",
    "\n",
    "        # Create a color map based on the labels\n",
    "        unique_labels = np.unique(self.node_subjects)\n",
    "        color_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        colors = [color_map[label] for label in self.node_subjects]\n",
    "\n",
    "        # Draw nodes and edges\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        nx.draw_networkx_nodes(G_nx, pos, node_size=50, node_color=colors, cmap=plt.get_cmap('Set1'), alpha=0.6)\n",
    "        nx.draw_networkx_edges(G_nx, pos, alpha=0.3)\n",
    "        \n",
    "        # Create a legend\n",
    "        handles = [plt.Line2D([0], [0], marker='o', color='w', label=label, \n",
    "                               markerfacecolor=plt.get_cmap('Set1')(color_map[label]), markersize=10) \n",
    "                   for label in unique_labels]\n",
    "        plt.legend(handles=handles, title=\"Classes\")\n",
    "        \n",
    "        plt.title(f\"{self.dataset_name.capitalize()} Dataset Citation Network\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbbe6837-bc9f-4c70-b3b4-9b92ad731401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The PubMed Diabetes dataset consists of 19717 scientific publications from PubMed database pertaining to diabetes classified into one of three classes. The citation network consists of 44338 links. Each publication in the dataset is described by a TF/IDF weighted word vector from a dictionary which consists of 500 unique words."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load PubMedDiabetes dataset\n",
    "dataset_name = 'pubmed'\n",
    "citation_visualizer = CitationNetworkVisualizer(dataset_name)\n",
    "feature_matrix, data, labels = citation_visualizer.load_data()\n",
    "unique_labels = set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65075907-4a03-48c2-9594-b3aeb08f6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation_visualizer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8cc138c-65ea-449f-9d23-d3d513a8c25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16c682d-c042-44dd-a939-3e193e03b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subdataset(adjacency_matrix, labels, feature_matrix, target_fraction, random_state=42, tolerance=0.02):\n",
    "    import numpy as np\n",
    "    import scipy.sparse as sp\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    total_nodes = len(labels)\n",
    "    target_size = int(total_nodes * target_fraction)\n",
    "    min_size = target_size - int(total_nodes * tolerance)\n",
    "    max_size = target_size + int(total_nodes * tolerance)\n",
    "\n",
    "    # Ensure the adjacency matrix is in CSR format\n",
    "    adjacency_matrix = sp.csr_matrix(adjacency_matrix)\n",
    "    adjacency_matrix.setdiag(0)\n",
    "    adjacency_matrix.eliminate_zeros()\n",
    "\n",
    "    node_indices = np.arange(total_nodes)\n",
    "    sampled_node_ids = set()\n",
    "    neighbors_included = set()\n",
    "\n",
    "    while True:\n",
    "        # Randomly sample nodes to try to reach target_size\n",
    "        sampled_node_ids = set(np.random.choice(node_indices, size=target_size, replace=False))\n",
    "\n",
    "        # Add neighbors\n",
    "        for node_id in sampled_node_ids:\n",
    "            neighbors = adjacency_matrix[node_id].indices\n",
    "            neighbors_included.update(neighbors)\n",
    "\n",
    "        # Combine sampled nodes and their neighbors\n",
    "        all_node_ids = sampled_node_ids.union(neighbors_included)\n",
    "        \n",
    "        # Ensure the combined size is within the tolerance\n",
    "        if min_size <= len(all_node_ids) <= max_size:\n",
    "            break\n",
    "        elif len(all_node_ids) < min_size:\n",
    "            target_size += int(0.05 * total_nodes)  # Increase target size\n",
    "        else:\n",
    "            target_size -= int(0.05 * total_nodes)  # Decrease target size\n",
    "\n",
    "        neighbors_included.clear()  # Reset for the next iteration\n",
    "\n",
    "    all_node_ids = np.array(list(all_node_ids))\n",
    "\n",
    "    # Create a mask for selected nodes\n",
    "    all_nodes_mask = np.zeros(total_nodes, dtype=bool)\n",
    "    all_nodes_mask[all_node_ids] = True\n",
    "\n",
    "    # Extract sub-adjacency matrix, labels, and features\n",
    "    sub_adj_matrix = adjacency_matrix[all_nodes_mask][:, all_nodes_mask]\n",
    "    sub_labels = labels[all_nodes_mask]\n",
    "    sub_features = feature_matrix[all_nodes_mask]\n",
    "\n",
    "    return sub_adj_matrix, sub_labels, sub_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5366f899-0426-4b2c-bcb8-4f4212748a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(adjacency_matrix, labels, feature_matrix):\n",
    "    # Ensure adjacency matrix is sparse\n",
    "    adjacency_matrix = sp.csr_matrix(adjacency_matrix)\n",
    "    \n",
    "    # Remove diagonal elements (self-loops)\n",
    "    adjacency_matrix.setdiag(0)\n",
    "    adjacency_matrix.eliminate_zeros()  # Remove explicit zeros\n",
    "    \n",
    "    # Calculate degree matrix (as a vector)\n",
    "    degree_vector = np.array(adjacency_matrix.sum(axis=1)).flatten()\n",
    "    \n",
    "    # Identify isolated nodes (degree == 0)\n",
    "    isolated_nodes = np.where(degree_vector == 0)[0]\n",
    "    non_isolated_mask = np.isin(np.arange(adjacency_matrix.shape[0]), isolated_nodes, invert=True)\n",
    "\n",
    "    # Filter adjacency matrix and labels for non-isolated nodes\n",
    "    adjacency_matrix_non_isolated = adjacency_matrix[non_isolated_mask][:, non_isolated_mask]\n",
    "    labels_non_isolated = labels[non_isolated_mask]\n",
    "    feature_matrix_non_isolated = feature_matrix[non_isolated_mask, :]\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels_non_isolated = label_encoder.fit_transform(labels_non_isolated)\n",
    "\n",
    "    return adjacency_matrix_non_isolated, encoded_labels_non_isolated, feature_matrix_non_isolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca1d5110-013f-44d5-8f1e-83d0f1cab9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(adjacency_matrix, labels, feature_matrix, nodes_file=\"nodes.csv\", edges_file=\"edges.csv\"):\n",
    "    \"\"\"Save the node and edge data into separate CSV files.\"\"\"\n",
    "    \n",
    "    # Save node information (ID, features, labels) to CSV\n",
    "    node_data = pd.DataFrame({\n",
    "        'id': np.arange(feature_matrix.shape[0]),\n",
    "        'features': [list(f) for f in feature_matrix],  # convert features to list\n",
    "        'label': labels\n",
    "    })\n",
    "    node_data.to_csv(nodes_file, index=False)\n",
    "\n",
    "    # Save adjacency matrix (edge list) to CSz\n",
    "    edges = np.argwhere(adjacency_matrix > 0)  # get index of non-zero entries (edges)\n",
    "    edge_list = pd.DataFrame(edges, columns=['source_id', 'target_id'])\n",
    "    edge_list.to_csv(edges_file, index=False)\n",
    "\n",
    "    print(f\"Nodes saved to {nodes_file} and edges saved to {edges_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ff4fa5b-0ce8-489b-9c38-2791af11a0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating subdataset with target fraction 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evi/.pyenv/versions/3.8.14/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual fraction after preprocessing: 0.32\n",
      "Nodes saved to pubmed_33/nodes.csv and edges saved to pubmed_33/edges.csv.\n",
      "Subdataset saved to folder: pubmed_33\n",
      "\n",
      "Generating subdataset with target fraction 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evi/.pyenv/versions/3.8.14/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual fraction after preprocessing: 0.65\n",
      "Nodes saved to pubmed_66/nodes.csv and edges saved to pubmed_66/edges.csv.\n",
      "Subdataset saved to folder: pubmed_66\n",
      "\n",
      "Generating subdataset with target fraction 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evi/.pyenv/versions/3.8.14/lib/python3.8/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual fraction after preprocessing: 1.00\n",
      "Nodes saved to pubmed_full/nodes.csv and edges saved to pubmed_full/edges.csv.\n",
      "Subdataset saved to folder: pubmed_full\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "fractions = [1/3, 2/3, 1.0]\n",
    "subdatasets = []\n",
    "tolerance = 0.02  # Allow 2% deviation\n",
    "\n",
    "# Folder names for subdatasets\n",
    "folder_names = [\"pubmed_33\", \"pubmed_66\", \"pubmed_full\"]\n",
    "\n",
    "for idx, fraction in enumerate(fractions):\n",
    "    print(f\"\\nGenerating subdataset with target fraction {fraction}\")\n",
    "    \n",
    "    # Generate subdataset\n",
    "    sub_adj_matrix, sub_labels, sub_features = generate_subdataset(\n",
    "        data, labels, feature_matrix, target_fraction=fraction, tolerance=tolerance\n",
    "    )\n",
    "    \n",
    "    # Preprocess the subdataset\n",
    "    sub_adj_matrix, sub_labels, sub_features = preprocess_data(\n",
    "        sub_adj_matrix, sub_labels, sub_features\n",
    "    )\n",
    "    \n",
    "    # Calculate actual fraction\n",
    "    actual_fraction = len(sub_labels) / len(labels)\n",
    "    print(f\"Actual fraction after preprocessing: {actual_fraction:.2f}\")\n",
    "    \n",
    "    # Append to subdatasets\n",
    "    subdatasets.append((sub_adj_matrix, sub_labels, sub_features))\n",
    "    \n",
    "    # Save the subdataset into its respective folder\n",
    "    folder_name = folder_names[idx]\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    \n",
    "    nodes_file = f\"{folder_name}/nodes.csv\"\n",
    "    edges_file = f\"{folder_name}/edges.csv\"\n",
    "    \n",
    "    save_to_csv(sub_adj_matrix, sub_labels, sub_features, nodes_file=nodes_file, edges_file=edges_file)\n",
    "    print(f\"Subdataset saved to folder: {folder_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25119fd2-22b0-4373-834b-bf1bf090ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fractions = [1/3, 2/3, 1.0]\n",
    "# subdatasets = []\n",
    "# tolerance = 0.02  # Allow 2% deviation\n",
    "\n",
    "# for fraction in fractions:\n",
    "#     print(f\"\\nGenerating subdataset with target fraction {fraction}\")\n",
    "#     sub_adj_matrix, sub_labels, sub_features = generate_subdataset(\n",
    "#         data, labels, feature_matrix, target_fraction=fraction, tolerance=tolerance\n",
    "#     )\n",
    "    \n",
    "#     # Preprocess the subdataset\n",
    "#     sub_adj_matrix, sub_labels, sub_features = preprocess_data(\n",
    "#         sub_adj_matrix, sub_labels, sub_features\n",
    "#     )\n",
    "    \n",
    "#     # Calculate actual fraction\n",
    "#     actual_fraction = len(sub_labels) / len(labels)\n",
    "#     print(f\"Actual fraction after preprocessing: {actual_fraction:.2f}\")\n",
    "    \n",
    "#     subdatasets.append((sub_adj_matrix, sub_labels, sub_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3981d933-417f-4d85-a051-5b3e8e0483b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save subdatasets to CSV files\n",
    "# for idx, (sub_adj_matrix, sub_labels, sub_features) in enumerate(subdatasets):\n",
    "#     nodes_file = f\"../nodes_pubmed_{idx}.csv\"\n",
    "#     edges_file = f\"../edges_pubmed_{idx}.csv\"\n",
    "#     save_to_csv(sub_adj_matrix, sub_labels, sub_features, nodes_file=nodes_file, edges_file=edges_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867a09a-0ae5-4f13-b145-b8ce3809d502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8.14",
   "language": "python",
   "name": "python3.8.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
