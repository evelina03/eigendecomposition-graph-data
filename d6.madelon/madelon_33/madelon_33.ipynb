{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890cd21c-dd04-4a75-8459-be4a0d7c1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eae9c44b-32eb-4639-9453-70e8bf118d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.495</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.774</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.526</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.463</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.558</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.426</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.683</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.293</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.439</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.426</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0.683</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8     9  ...  \\\n",
       "0    0.390  0.506  0.511  0.364  0.665  0.304  0.347  0.455  0.436  0.66  ...   \n",
       "1    0.585  0.815  0.641  0.636  0.274  0.630  0.426  0.727  0.154  0.44  ...   \n",
       "2    0.585  0.575  0.609  0.515  0.439  0.391  0.610  0.727  0.410  0.48  ...   \n",
       "3    0.463  0.588  0.430  0.455  0.692  0.761  0.347  0.727  0.470  0.44  ...   \n",
       "4    0.341  0.511  0.673  0.424  0.415  0.196  0.675  0.455  0.487  0.12  ...   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...   ...  ...   \n",
       "853  0.683  0.408  0.264  0.591  0.165  0.413  0.538  0.273  0.427  0.48  ...   \n",
       "854  0.293  0.708  0.489  0.500  0.479  0.522  0.610  0.545  0.239  0.56  ...   \n",
       "855  0.512  0.459  0.613  0.470  0.366  0.587  0.458  0.545  0.812  0.46  ...   \n",
       "856  0.439  0.391  0.296  0.394  0.616  0.413  0.469  0.364  0.274  0.42  ...   \n",
       "857  0.683  0.464  0.401  0.561  0.220  0.587  0.549  0.455  0.556  0.86  ...   \n",
       "\n",
       "       491    492    493    494    495    496   497    498    499  target  \n",
       "0    0.324  0.539  0.206  0.709  0.734  0.535  0.55  0.459  0.495      -1  \n",
       "1    0.441  0.317  0.411  0.543  0.383  0.442  0.38  0.320  0.774      -1  \n",
       "2    0.412  0.500  0.453  0.603  0.448  0.488  0.62  0.488  0.526      -1  \n",
       "3    0.529  0.122  0.508  0.138  0.477  0.442  0.73  0.523  0.558      -1  \n",
       "4    0.441  0.444  0.509  0.360  0.555  0.488  0.61  0.616  0.426      -1  \n",
       "..     ...    ...    ...    ...    ...    ...   ...    ...    ...     ...  \n",
       "853  0.206  0.506  0.404  0.514  0.610  0.419  0.50  0.665  0.526       1  \n",
       "854  0.382  0.561  0.614  0.664  0.510  0.419  0.55  0.587  0.474       1  \n",
       "855  0.382  0.450  0.388  0.514  0.370  0.488  0.44  0.399  0.558       1  \n",
       "856  0.353  0.356  0.215  0.441  0.503  0.512  0.42  0.488  0.426       1  \n",
       "857  0.471  0.333  0.518  0.692  0.562  0.605  0.49  0.402  0.289       1  \n",
       "\n",
       "[858 rows x 501 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load Subdatasets\n",
    "def load_subdataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "data = load_subdataset('madelon_33.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24c83a8-a1a1-4b60-856d-75a3b31269b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, -1}\n"
     ]
    }
   ],
   "source": [
    "true_labels = data[\"target\"].tolist()\n",
    "unique_labels = set(true_labels)\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9193cd70-5f7b-4cd9-8ca3-c6274f705cb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.463</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.683</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>0.293</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>0.512</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>0.439</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0.683</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>858 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8     9  ...  \\\n",
       "0    0.390  0.506  0.511  0.364  0.665  0.304  0.347  0.455  0.436  0.66  ...   \n",
       "1    0.585  0.815  0.641  0.636  0.274  0.630  0.426  0.727  0.154  0.44  ...   \n",
       "2    0.585  0.575  0.609  0.515  0.439  0.391  0.610  0.727  0.410  0.48  ...   \n",
       "3    0.463  0.588  0.430  0.455  0.692  0.761  0.347  0.727  0.470  0.44  ...   \n",
       "4    0.341  0.511  0.673  0.424  0.415  0.196  0.675  0.455  0.487  0.12  ...   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...   ...  ...   \n",
       "853  0.683  0.408  0.264  0.591  0.165  0.413  0.538  0.273  0.427  0.48  ...   \n",
       "854  0.293  0.708  0.489  0.500  0.479  0.522  0.610  0.545  0.239  0.56  ...   \n",
       "855  0.512  0.459  0.613  0.470  0.366  0.587  0.458  0.545  0.812  0.46  ...   \n",
       "856  0.439  0.391  0.296  0.394  0.616  0.413  0.469  0.364  0.274  0.42  ...   \n",
       "857  0.683  0.464  0.401  0.561  0.220  0.587  0.549  0.455  0.556  0.86  ...   \n",
       "\n",
       "       490    491    492    493    494    495    496   497    498    499  \n",
       "0    0.479  0.324  0.539  0.206  0.709  0.734  0.535  0.55  0.459  0.495  \n",
       "1    0.352  0.441  0.317  0.411  0.543  0.383  0.442  0.38  0.320  0.774  \n",
       "2    0.324  0.412  0.500  0.453  0.603  0.448  0.488  0.62  0.488  0.526  \n",
       "3    0.261  0.529  0.122  0.508  0.138  0.477  0.442  0.73  0.523  0.558  \n",
       "4    0.500  0.441  0.444  0.509  0.360  0.555  0.488  0.61  0.616  0.426  \n",
       "..     ...    ...    ...    ...    ...    ...    ...   ...    ...    ...  \n",
       "853  0.613  0.206  0.506  0.404  0.514  0.610  0.419  0.50  0.665  0.526  \n",
       "854  0.465  0.382  0.561  0.614  0.664  0.510  0.419  0.55  0.587  0.474  \n",
       "855  0.394  0.382  0.450  0.388  0.514  0.370  0.488  0.44  0.399  0.558  \n",
       "856  0.472  0.353  0.356  0.215  0.441  0.503  0.512  0.42  0.488  0.426  \n",
       "857  0.507  0.471  0.333  0.518  0.692  0.562  0.605  0.49  0.402  0.289  \n",
       "\n",
       "[858 rows x 500 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = data.drop([\"Index\",\"target\"], axis=1)\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb3ac7e-1097-48e4-a54b-8ee8250ce3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_clustering(dataframe, labels, similarity_graph, laplacian, number_of_clusters, local_sigma = None, epsilon = None, k_knn = None, k_mknn = None):\n",
    "\n",
    "    # Pairwise distances\n",
    "    dimension = dataframe.shape[0]\n",
    "    dist_mat = squareform(pdist(dataframe))\n",
    "\n",
    "    if similarity_graph == \"full\":\n",
    "\n",
    "        #calculate local sigma\n",
    "        sigmas = np.zeros(dimension)\n",
    "        for i in tqdm(range(len(dist_mat))):\n",
    "            sigmas[i] = sorted(dist_mat[i])[local_sigma]\n",
    "\n",
    "        # Adjaceny matrix with optimal sigma\n",
    "        adjacency_matrix = np.zeros([dimension, dimension])\n",
    "        for i in tqdm(range(dimension)):\n",
    "            for j in range(i+1, dimension):\n",
    "                d = np.exp(-1*dist_mat[i,j]**2/(sigmas[i]*sigmas[j]))\n",
    "                adjacency_matrix[i,j] = d\n",
    "                adjacency_matrix[j,i] = d\n",
    "\n",
    "\n",
    "    elif similarity_graph == \"eps\":\n",
    "\n",
    "        # Adjaceny matrix with epsilon threshold\n",
    "        adjacency_matrix = np.zeros([dimension, dimension])\n",
    "\n",
    "        for i in tqdm(range(dimension)):\n",
    "            for j in range(i+1, dimension):\n",
    "                if dist_mat[i,j] < epsilon:\n",
    "                    d = 1\n",
    "                else:\n",
    "                    d = 0\n",
    "                adjacency_matrix[i,j] = d\n",
    "                adjacency_matrix[j,i] = d\n",
    "\n",
    "\n",
    "    elif similarity_graph == \"knn\":\n",
    "\n",
    "        # Adjaceny matrix with k-neighbours\n",
    "        adjacency_matrix = np.zeros([dimension, dimension])\n",
    "\n",
    "        for i in tqdm(range(dimension)):\n",
    "            # Sort distances for node i and get indices of the k nearest neighbors\n",
    "            sorted_indices = np.argsort(dist_mat[i])\n",
    "            k_nearest_indices = sorted_indices[1:k_knn+1]  # Exclude the node itself\n",
    "\n",
    "            # Update the adjacency matrix\n",
    "            adjacency_matrix[i, k_nearest_indices] = 1\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        # Adjaceny matrix with mutual k-neighbours\n",
    "        adjacency_matrix = np.zeros([dimension, dimension])\n",
    "\n",
    "        for i in tqdm(range(dimension)):\n",
    "            # Sort distances for node i and get indices of the k nearest neighbors\n",
    "            sorted_indices = np.argsort(dist_mat[i])\n",
    "            k_nearest_indices = sorted_indices[1:k_mknn+1]  # Exclude the node itself\n",
    "\n",
    "            for neighbor in k_nearest_indices:\n",
    "                # Check if node i is also among the k-nearest neighbors of the current neighbor\n",
    "                neighbor_sorted_indices = np.argsort(dist_mat[neighbor])\n",
    "                if i in neighbor_sorted_indices[1:k_mknn+1]:\n",
    "                    # Connect nodes if they are mutual k-nearest neighbors\n",
    "                    adjacency_matrix[i, neighbor] = 1\n",
    "                    adjacency_matrix[neighbor, i] = 1\n",
    "\n",
    "    # Calculate degree matrix\n",
    "    degrees = np.sum(adjacency_matrix, axis=1)\n",
    "    degree_matrix = np.diag(degrees)\n",
    "\n",
    "    if laplacian == \"sym\":\n",
    "\n",
    "        # Normalized Symmetric laplacian matrix\n",
    "        d_inv_sqrt = np.zeros_like(degrees)\n",
    "        nonzero = degrees > 0\n",
    "        d_inv_sqrt[nonzero] = 1.0 / np.sqrt(degrees[nonzero])\n",
    "        d_half = np.diag(d_inv_sqrt)\n",
    "        laplacian_matrix_normalized = d_half @ adjacency_matrix @ d_half\n",
    "\n",
    "    if laplacian == \"rw\":\n",
    "\n",
    "        # Normalized Random Walk laplacian matrix\n",
    "        d_inv = np.zeros_like(degrees)\n",
    "        nonzero = degrees > 0\n",
    "        d_inv[nonzero] = 1.0 / degrees[nonzero]\n",
    "        d_inverse = np.diag(d_inv)\n",
    "        laplacian_matrix_normalized = d_inverse @ adjacency_matrix\n",
    "\n",
    "    if laplacian == \"ad\":\n",
    "\n",
    "        # Adaptive Laplacian matrix\n",
    "        D_local = np.zeros_like(degrees)\n",
    "        for i in range(len(degrees)):\n",
    "            neighbors = np.where(adjacency_matrix[i] > 0)[0]\n",
    "            if len(neighbors) > 0 and degrees[i] > 0:\n",
    "                D_local[i] = np.sum(degrees[neighbors]) / degrees[i]\n",
    "            else:\n",
    "                D_local[i] = 0\n",
    "        D_local_inv_sqrt = np.zeros_like(D_local)\n",
    "        nonzero = D_local > 0\n",
    "        D_local_inv_sqrt[nonzero] = 1.0 / np.sqrt(D_local[nonzero])\n",
    "        D_local_inv = np.diag(D_local_inv_sqrt)\n",
    "        laplacian_matrix_normalized = D_local_inv @ adjacency_matrix @ D_local_inv\n",
    "\n",
    "    if check_symmetric(laplacian_matrix_normalized) :\n",
    "        # Calculating eigenvalues and eigenvectors for symmetric matrix\n",
    "        e, v = np.linalg.eigh(laplacian_matrix_normalized)\n",
    "    else:\n",
    "        # Calculating eigenvalues and eigenvectors for non-symmetric matrix\n",
    "        e, v = np.linalg.eig(laplacian_matrix_normalized)\n",
    "        idx = np.argsort(np.real(e))\n",
    "        e = np.real(e[idx])\n",
    "        v = np.real(v[:, idx])\n",
    "\n",
    "    # Calculate eigengap\n",
    "    eigengap = np.diff(e)\n",
    "    optimal_number_of_clusters = np.argmax(eigengap[:10]) + 1\n",
    "\n",
    "    if number_of_clusters != None:\n",
    "        # First case: k\n",
    "        n_clusters = max(number_of_clusters,2)\n",
    "    else:\n",
    "        # Second case: optimal number of clusters from eigengap\n",
    "        n_clusters = max(optimal_number_of_clusters,2)\n",
    "\n",
    "    results = []\n",
    "    # adj_filename, laplacian_filename, X_filename = save_matrices(similarity_graph,laplacian, adjacency_matrix, laplacian_matrix_normalized, X)\n",
    "\n",
    "    # KMeans clustering\n",
    "    X = v[:, -n_clusters:]\n",
    "    clustering = KMeans(n_clusters=n_clusters, random_state=42, n_init=100)\n",
    "    cluster_labels = clustering.fit_predict(X)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    sil_score = silhouette_score(dataframe, cluster_labels)\n",
    "    ar_score = adjusted_rand_score(labels, cluster_labels)\n",
    "\n",
    "    results.append((sil_score, ar_score, n_clusters,cluster_labels))\n",
    "    # results.append((sil_score, ar_score, n_clusters,cluster_labels, adj_filename, laplacian_filename, X_filename))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a11e1776-0995-4453-8b62-5a75b65505ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bab420-148e-456c-a3d6-64c2c9130381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate dynamic ranges based on data size and pairwise distances\n",
    "def get_dynamic_search_space(data):\n",
    "    # Number of points in the dataset\n",
    "    n = data.shape[0]\n",
    "\n",
    "    # Compute pairwise distances\n",
    "    dist_mat = squareform(pdist(data))\n",
    "    flat_distances = dist_mat[np.tril_indices(n, -1)]\n",
    "\n",
    "    # Dynamic range for local_sigma (based on square root of n)\n",
    "    local_sigma_min = max(1, int(np.sqrt(n) / 2))\n",
    "    local_sigma_max = int(np.sqrt(n))\n",
    "    \n",
    "    # Dynamic range for epsilon (based on distance percentiles)\n",
    "    epsilon_min = np.percentile(flat_distances, 80)  # 80th percentile\n",
    "    epsilon_max = np.percentile(flat_distances, 95)  # 95th percentile\n",
    "    \n",
    "    # Dynamic range for k (based on number of data points)\n",
    "    k_min = max(5, int(0.01 * n))  # 1% of dataset size, but at least 5\n",
    "    k_max = min(int(0.2 * n), n - 1)  # 20% of dataset size, but never more than n-1\n",
    "    \n",
    "    # Ensure k_min does not exceed k_max\n",
    "    if k_min > k_max:\n",
    "        k_min = max(5, int(0.01 * n))  # Keep dynamic range based on percentage but within limits\n",
    "    \n",
    "    return (local_sigma_min, local_sigma_max), (epsilon_min, epsilon_max), (k_min, k_max)\n",
    "\n",
    "# Optimization functions for each parameter\n",
    "\n",
    "# Optimize local_sigma for \"full\" graph\n",
    "def optimize_local_sigma(data, labels, laplacians, number_of_clusters):\n",
    "    (local_sigma_min, local_sigma_max), _, _ = get_dynamic_search_space(data)\n",
    "\n",
    "    def objective_local_sigma(local_sigma):\n",
    "        silhouette_scores = []\n",
    "        local_sigma = int(local_sigma[0])\n",
    "        try:\n",
    "            for laplacian in laplacians:\n",
    "                results = spectral_clustering(data, labels, similarity_graph=\"full\", laplacian=laplacian, number_of_clusters=number_of_clusters, local_sigma=local_sigma)\n",
    "                silhouette_scores.append(results[0][0])\n",
    "            return -np.mean(silhouette_scores)\n",
    "        except (ValueError, np.linalg.LinAlgError) as e:\n",
    "            print(f\"Skipping local_sigma={local_sigma} due to error: {e}\")\n",
    "            return 1e6  # Return a large value to penalize the failed set of hyperparameters\n",
    "\n",
    "    result = gp_minimize(objective_local_sigma, [(local_sigma_min, local_sigma_max)], n_calls=20, n_random_starts=10, random_state=42)\n",
    "\n",
    "    if result.fun < 1e6:\n",
    "        best_local_sigma = result.x[0]\n",
    "        print(f\"Best local sigma: {best_local_sigma}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"No valid local_sigma found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Optimize epsilon for \"eps\" graph\n",
    "def optimize_epsilon(data, labels, laplacians, number_of_clusters):\n",
    "    _, (epsilon_min, epsilon_max), _ = get_dynamic_search_space(data)\n",
    "\n",
    "    def objective_epsilon(epsilon):\n",
    "        silhouette_scores = []\n",
    "        epsilon = float(epsilon[0])\n",
    "        try:\n",
    "            for laplacian in laplacians:\n",
    "                results = spectral_clustering(data, labels, similarity_graph=\"eps\", laplacian=laplacian, number_of_clusters=number_of_clusters, epsilon=epsilon)\n",
    "                silhouette_scores.append(results[0][0])\n",
    "            return -np.mean(silhouette_scores)\n",
    "        except (ValueError, np.linalg.LinAlgError) as e:\n",
    "            print(f\"Skipping epsilon={epsilon} due to error: {e}\")\n",
    "            return 1e6  # Return a large value to penalize the failed set of hyperparameters\n",
    "\n",
    "    result = gp_minimize(objective_epsilon, [(epsilon_min, epsilon_max)], n_calls=20, n_random_starts=10, random_state=42)\n",
    "\n",
    "    if result.fun < 1e6:\n",
    "        epsilon = result.x[0]\n",
    "        print(f\"Best epsilon: {epsilon}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"No valid epsilon found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Optimize k for \"knn\" graph\n",
    "def optimize_k_knn(data, labels, laplacians, number_of_clusters):\n",
    "    _, _, (k_min, k_max) = get_dynamic_search_space(data)\n",
    "\n",
    "    def objective_k_knn(k):\n",
    "        silhouette_scores = []\n",
    "        k = int(k[0])\n",
    "        try:\n",
    "            for laplacian in laplacians:\n",
    "                results = spectral_clustering(data, labels, similarity_graph=\"knn\", laplacian=laplacian, number_of_clusters=number_of_clusters, k_knn=k)\n",
    "                silhouette_scores.append(results[0][0])\n",
    "            return -np.mean(silhouette_scores)\n",
    "        except (ValueError, np.linalg.LinAlgError) as e:\n",
    "            print(f\"Skipping k={k} due to error: {e}\")\n",
    "            return 1e6  # Return a large value to penalize the failed set of hyperparameters\n",
    "\n",
    "    result = gp_minimize(objective_k_knn, [(k_min, k_max)], n_calls=20, n_random_starts=10, random_state=42)\n",
    "\n",
    "    if result.fun < 1e6:\n",
    "        k_knn = result.x[0]\n",
    "        print(f\"Best k for knn: {k_knn}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"No valid k for knn found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Optimize k for \"mknn\" graph\n",
    "def optimize_k_mknn(data, labels, laplacians, number_of_clusters):\n",
    "    _, _, (k_min, k_max) = get_dynamic_search_space(data)\n",
    "\n",
    "    def objective_k_mknn(k):\n",
    "        silhouette_scores = []\n",
    "        k = int(k[0])\n",
    "        try:\n",
    "            for laplacian in laplacians:\n",
    "                results = spectral_clustering(data, labels, similarity_graph=\"mknn\", laplacian=laplacian, number_of_clusters=number_of_clusters, k_mknn=k)\n",
    "                silhouette_scores.append(results[0][0])\n",
    "            return -np.mean(silhouette_scores)\n",
    "        except (ValueError, np.linalg.LinAlgError) as e:\n",
    "            print(f\"Skipping k={k} due to error: {e}\")\n",
    "            return 1e6  # Return a large value to penalize the failed set of hyperparameters\n",
    "\n",
    "    result = gp_minimize(objective_k_mknn, [(k_min, k_max)], n_calls=20, n_random_starts=10, random_state=42)\n",
    "\n",
    "    if result.fun < 1e6:\n",
    "        k_mknn = result.x[0]\n",
    "        print(f\"Best k for mknn: {k_mknn}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"No valid k for mknn found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1d891-766c-4327-a314-b7be2800f1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5064.82it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1829.49it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4813.55it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1837.14it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4429.01it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1844.24it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4709.24it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1813.70it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4369.95it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1833.87it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4625.43it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1815.50it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4456.54it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1822.17it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4553.89it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1844.57it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4729.34it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1844.42it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4772.84it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1847.16it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4673.05it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1840.95it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4676.80it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1861.49it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4700.70it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1841.90it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4717.66it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1853.31it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4669.74it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1837.37it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4856.68it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1809.34it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4591.23it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1827.73it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4338.92it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1818.38it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4669.64it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1821.18it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4623.67it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1811.13it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4692.42it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1803.03it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4483.46it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1793.49it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4780.42it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1812.06it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4551.22it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1826.80it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4566.92it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1821.93it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4595.21it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1824.64it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4869.88it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1836.88it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4632.53it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1834.62it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4660.97it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1819.11it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4373.40it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1834.38it/s]\n",
      "/Users/evi/.pyenv/versions/3.8.14/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [15] before, using random point [23]\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4916.06it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1840.79it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4478.05it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1844.92it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4521.46it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1825.87it/s]\n",
      "/Users/evi/.pyenv/versions/3.8.14/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [21] before, using random point [26]\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4191.50it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1821.54it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4839.72it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1842.51it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4832.55it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1841.01it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4951.95it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1831.17it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4768.57it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1839.21it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4739.15it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1817.10it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4992.76it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1840.23it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4484.36it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1841.02it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4596.50it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1841.79it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4906.92it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1789.51it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4594.74it/s]\n",
      "100%|█████████████████████████████████████████| 858/858 [03:46<00:00,  3.79it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4506.24it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1796.90it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4836.10it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1807.57it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4585.52it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1787.05it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4593.69it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1810.42it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4962.46it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1827.01it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4239.97it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1820.36it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4443.36it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1837.31it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5034.62it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1831.83it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4711.10it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1829.05it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4317.90it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1842.58it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4910.06it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1825.81it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4866.56it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1842.99it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4545.53it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1812.68it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4970.65it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1796.24it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4952.29it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1823.25it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4721.34it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1805.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best local sigma: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5102.34it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4749.70it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4805.73it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4505.40it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4450.46it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4527.18it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4241.08it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4812.19it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4504.31it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4735.26it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5010.66it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4781.30it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5113.90it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4887.02it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4926.67it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4208.11it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4960.63it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4714.78it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4659.85it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4550.88it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4729.73it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4552.09it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4875.84it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4755.54it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5037.85it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5195.41it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4611.88it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4879.19it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4740.68it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4902.89it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4013.02it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4889.22it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 2955.72it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5032.10it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4193.22it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 3426.53it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5259.96it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4760.59it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4604.68it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 2382.91it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4956.84it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 4526.80it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 5107.06it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 1763.20it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 2397.99it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 3664.77it/s]\n",
      "100%|███████████████████████████████████████| 858/858 [00:00<00:00, 3710.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Call the optimization functions\n",
    "laplacian_methods = [\"sym\", \"rw\", \"ad\"]\n",
    "number_of_clusters = 2\n",
    "\n",
    "# Optimize local_sigma for \"full\" graph\n",
    "result_local_sigma = optimize_local_sigma(data_cleaned, true_labels, laplacian_methods, number_of_clusters)\n",
    "best_local_sigma = result_local_sigma.x[0]\n",
    "\n",
    "# Optimize epsilon for \"eps\" graph\n",
    "result_epsilon = optimize_epsilon(data_cleaned, true_labels, laplacian_methods, number_of_clusters)\n",
    "best_epsilon = round(result_epsilon.x[0], 3)\n",
    "\n",
    "# Optimize k for \"knn\" graph\n",
    "result_k_knn = optimize_k_knn(data_cleaned, true_labels, laplacian_methods, number_of_clusters)\n",
    "best_k_knn = result_k_knn.x[0]\n",
    "\n",
    "# Optimize k for \"mknn\" graph\n",
    "result_k_mknn = optimize_k_mknn(data_cleaned, true_labels, laplacian_methods, number_of_clusters)\n",
    "best_k_mknn = result_k_mknn.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59c345-ce46-4e94-a800-beb0e0bae718",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_graphs = [\"full\", \"eps\", \"knn\", \"mknn\"]\n",
    "laplacian_methods = [\"sym\", \"rw\",\"ad\"]\n",
    "number_of_clusters = 3\n",
    "# best_local_sigma = 11\n",
    "# best_epsilon = 5\n",
    "# best_k_knn = 29\n",
    "# best_k_mknn = 28\n",
    "\n",
    "silhouette_scores = []\n",
    "adjusted_rand_scores = []\n",
    "clusters = []\n",
    "sim_graph = []\n",
    "laplacian = []\n",
    "cluster_labels = []\n",
    "hyperparameters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdda230-9c6f-4d4a-8198-6c0e8e07d354",
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in similarity_graphs:\n",
    "\n",
    "    for laplace in laplacian_methods:\n",
    "        metrics = spectral_clustering(data_cleaned, true_labels, graph, laplace, number_of_clusters, best_local_sigma, best_epsilon, best_k_knn, best_k_mknn)\n",
    "        # metrics, adj_file, lap_file, X_file = spectral_clustering(data_df, true_labels, graph, laplace, number_of_clusters, best_local_sigma, best_epsilon, best_k_knn, best_k_mknn)\n",
    "\n",
    "        for si, ar, cl, l in metrics:\n",
    "            sim_graph.append(graph)\n",
    "            laplacian.append(laplace)\n",
    "            silhouette_scores.append(si)\n",
    "            adjusted_rand_scores.append(ar)\n",
    "            clusters.append(cl)\n",
    "            cluster_labels.append(l)\n",
    "            # Append consolidated hyperparameters for each similarity graph type\n",
    "            if graph == \"full\":\n",
    "                hyperparameters.append(f\"local_sigma={best_local_sigma}\")\n",
    "            elif graph == \"eps\":\n",
    "                hyperparameters.append(f\"epsilon={best_epsilon}\")\n",
    "            elif graph == \"knn\":\n",
    "                hyperparameters.append(f\"k_nn={best_k_knn}\")\n",
    "            elif graph == \"mknn\":\n",
    "                hyperparameters.append(f\"k_mknn={best_k_mknn}\")\n",
    "            else:\n",
    "                hyperparameters.append(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f5772-8fd5-4267-b4c8-0103600d40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_madelon = pd.DataFrame(list(zip(sim_graph,laplacian,silhouette_scores,adjusted_rand_scores,clusters, hyperparameters, cluster_labels)),\n",
    "             columns= [\"graph\",\"laplacian\", \"silhouette\", \"adjusted_rand\",\"number_of_clusters\",\"hyperparameters\", \"cluster_labels\"])\n",
    "experiment_madelon[\"graph_laplacian\"] = experiment_iris[\"graph\"] + \"_\" + experiment_iris[\"laplacian\"]\n",
    "experiment_madelon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2118d-6e73-47b0-a4a6-768499610a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "experiment_madelon.to_csv('experiment_madelon_33.csv', index=False)\n",
    "\n",
    "# File is now saved in the current working directory\n",
    "print(\"CSV file saved as 'experiment_madelon_33.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
